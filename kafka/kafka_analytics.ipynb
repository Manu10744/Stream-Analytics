{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Kafka Streaming Analytics\n",
    "In this notebook Apache Kafka is going to be used and analyzed with reference to the streaming performance using the twitter dataset.\n",
    "\n",
    "In this case, we are going to use only one **Kafka Broker** that streams the data to the **Kafka Consumer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confluent-kafka\n",
      "  Downloading confluent_kafka-1.6.1-cp37-cp37m-manylinux2010_x86_64.whl (2.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7 MB 6.5 MB/s eta 0:00:01     |██████████████████████████▋     | 2.3 MB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: confluent-kafka\n",
      "Successfully installed confluent-kafka-1.6.1\n"
     ]
    }
   ],
   "source": [
    "# Install the Python Client for Apache Kafka\n",
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies and set constants\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from confluent_kafka import Producer, Consumer, KafkaError\n",
    "\n",
    "DATA_GENERATION_IN_MB = 1000 # ~ 1GB\n",
    "DATASET_SIZE_MB = 10\n",
    "TWITTER_DATA_PATH = \"../data/dataset.json\"\n",
    "KAFKA_TOPIC_TWITTER = \"twitter-stream\"\n",
    "CONSUMER_GROUP_ID = \"twitter-consumers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder: Running Kafka Architecture required\n",
    "The following cells assume a running Apache Kafka Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the data / write it to the Kafka Cluster\n",
    "producer_config = {\n",
    "    \"bootstrap.servers\": \"localhost:9092\"\n",
    "}\n",
    "p = Producer(producer_config)\n",
    "\n",
    "# Fill the topic with the specified amount of data\n",
    "generation_steps = int(DATA_GENERATION_IN_MB / DATASET_SIZE_MB)\n",
    "with open(TWITTER_DATA_PATH, \"r\") as dataset:\n",
    "    for step in range(generation_steps):\n",
    "        print(f\"Executing data generation step {step}...\")\n",
    "        dataset.seek(0) # Jump back to first line  \n",
    " \n",
    "        for tweet in dataset:\n",
    "            try:\n",
    "                p.produce(KAFKA_TOPIC_TWITTER, value=tweet)\n",
    "            except BufferError:\n",
    "                print('[INFO] Local producer queue is full (%d messages awaiting delivery): Trying again after flushing...\\n' % len(p)) \n",
    "                p.poll(0)\n",
    "\n",
    "                p.flush() # Send the messages in the queue\n",
    "\n",
    "                # The tweet that caused the BufferError could not be sent, so after flushing, we can now send it\n",
    "                p.produce(KAFKA_TOPIC_TWITTER, value=tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kafka_stats(json_stats_bytes):\n",
    "    \"\"\" Callback for the Apache Kafka Consumer Configuration which \n",
    "    requests performance metrics / statistics from Kafka. \n",
    "    \n",
    "    :param json_stats: The JSON statistics data in bytes\n",
    "    \"\"\"\n",
    "    # Decode the bytes into a python dictionary representing the JSON\n",
    "    stats = json.loads(json_stats_bytes)\n",
    "    # TODO: Check if we can actually use those statistics. If so, uncomment them in the consumer config\n",
    "    \n",
    "# Consume the data\n",
    "consumer_config = {\n",
    "    \"bootstrap.servers\": \"localhost:9092\",\n",
    "    \"group.id\": CONSUMER_GROUP_ID,\n",
    "    \"client.id\": \"client-1\",\n",
    "    \"stats_cb\": get_kafka_stats,\n",
    "#     \"statistics.interval.ms\": 20,\n",
    "#     'api.version.request': True,\n",
    "    \"enable.auto.commit\": True,\n",
    "    \"session.timeout.ms\": 6000,\n",
    "    \"default.topic.config\": {\"auto.offset.reset\": \"smallest\"}\n",
    "}\n",
    "c = Consumer(consumer_config)\n",
    "\n",
    "c.subscribe([KAFKA_TOPIC_TWITTER])\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        msg = c.poll(0.1)\n",
    "        \n",
    "        if msg is None:\n",
    "            continue\n",
    "        elif not msg.error():\n",
    "            msg_count += 1\n",
    "            print(f\"Received message {msg_count}\")\n",
    "        \n",
    "            # Display the received tweet\n",
    "            #tweet_json = json.loads(msg.value())\n",
    "            #print(json.dumps(tweet_json, indent=4, ensure_ascii=False, sort_keys=True))\n",
    "        elif msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "            print(\"End of partition reached {}/{}\".format(msg.topic(), msg.partition()))\n",
    "        else:\n",
    "            print(\"Error occured: {}\".format(msg.error().str()))\n",
    "except KeyBoardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    c.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
