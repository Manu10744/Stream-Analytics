{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Kafka Streaming Analytics\n",
    "### One Broker Setup\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "#### Component: Producer\n",
    "In this notebook Apache Kafka is going to be used and analyzed with reference to the streaming performance using the twitter dataset.\n",
    "\n",
    "In this case, we are going to use only one **Kafka Broker** that streams the data to the **Kafka Consumer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Python Client for Apache Kafka\n",
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies and set constants\n",
    "from confluent_kafka import Producer\n",
    "\n",
    "DATA_GENERATION_IN_MB = 1000 # ~ 1GB\n",
    "DATASET_SIZE_MB = 10\n",
    "\n",
    "TWITTER_DATA_PATH = \"/home/ubuntu/Stream-Analytics/data/dataset.json\"\n",
    "KAFKA_TOPIC_TWITTER = \"twitter-stream\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder: Running Kafka Architecture required\n",
    "The following cells assume a running Apache Kafka Environment.\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "Furthermore, as we are using the **Producer** component here, we have to make sure that the **Consumer** component is already running / expecting streaming data to ensure a performance measurement under realistic circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing data generation step 0...\n",
      "Data generation done!\n"
     ]
    }
   ],
   "source": [
    "# Produce the data / write it to the Kafka Cluster\n",
    "producer_config = {\n",
    "    \"bootstrap.servers\": \"localhost:9092\"\n",
    "}\n",
    "p = Producer(producer_config)\n",
    "\n",
    "# Fill the topic with the specified amount of data\n",
    "generation_steps = int(DATA_GENERATION_IN_MB / DATASET_SIZE_MB)\n",
    "with open(TWITTER_DATA_PATH, \"r\") as dataset:\n",
    "    for step in range(generation_steps):\n",
    "        print(f\"Executing data generation step {step}...\")\n",
    "        dataset.seek(0) # Jump back to first line  \n",
    " \n",
    "        for tweet in dataset:\n",
    "            try:\n",
    "                p.produce(KAFKA_TOPIC_TWITTER, value=tweet)\n",
    "            except BufferError:\n",
    "                print('[INFO] Local producer queue is full (%d messages awaiting delivery): Trying again after flushing...\\n' % len(p)) \n",
    "                p.poll(0)\n",
    "\n",
    "                p.flush() # Send the messages in the queue\n",
    "\n",
    "                # The tweet that caused the BufferError could not be sent, so after flushing, we can now send it\n",
    "                p.produce(KAFKA_TOPIC_TWITTER, value=tweet)\n",
    "                \n",
    "print(\"Data generation done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
