{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Kafka Streaming Analytics\n",
    "### One Broker Setup\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "#### Component: Producer\n",
    "In this notebook Apache Kafka is going to be used and analyzed with reference to the streaming performance using the twitter dataset.\n",
    "\n",
    "In this case, we are going to use only one **Kafka Broker** that streams the data to the **Kafka Consumer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Python Client for Apache Kafka\n",
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies and set constants\n",
    "import matplotlib.pyplot as plt\n",
    "import platform, socket, json, psutil, logging, multiprocessing\n",
    "\n",
    "from confluent_kafka import Producer\n",
    "from time import time, perf_counter\n",
    "from statistics import mean\n",
    "\n",
    "DATASET_SIZE_IN_MB = 10\n",
    "DATASET_SIZE_IN_MSGS = 14485\n",
    "\n",
    "TWITTER_DATA_PATH = \"/home/ubuntu/Stream-Analytics/data/dataset.json\"\n",
    "KAFKA_TOPIC_TWITTER = \"twitter-stream\"\n",
    "\n",
    "def get_system_info():\n",
    "    \"\"\" Returns system information as JSON. \"\"\"\n",
    "    try:\n",
    "        info = {}\n",
    "        info['platform'] = platform.system()\n",
    "        info['platform-version'] = platform.version()\n",
    "        info['hostname'] = socket.gethostname()\n",
    "        info['ram'] = str(round(psutil.virtual_memory().total / (1024.0 **3))) + \" GB\"\n",
    "        info['vCPUs'] = multiprocessing.cpu_count()\n",
    "        info['architecture'] = platform.machine()\n",
    "\n",
    "        return json.dumps(info, indent=4)\n",
    "    except Exception as e:\n",
    "        logging.exception(e)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder: Running Kafka Architecture required\n",
    "The following cells assume a running Apache Kafka Environment.\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "Furthermore, as we are using the **Producer** component here, we have to make sure that the **Consumer** component is already running / expecting streaming data to ensure a performance measurement under realistic circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"platform\": \"Linux\",\n",
      "    \"platform-version\": \"#80-Ubuntu SMP Mon Apr 12 17:35:00 UTC 2021\",\n",
      "    \"hostname\": \"kafka-master\",\n",
      "    \"ram\": \"9 GB\",\n",
      "    \"vCPUs\": 2,\n",
      "    \"architecture\": \"x86_64\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print system information\n",
    "print(get_system_info())\n",
    "\n",
    "# Produce the data / write it to the Kafka Cluster\n",
    "producer_config = {\n",
    "    \"bootstrap.servers\": \"localhost:9092\",\n",
    "    'queue.buffering.max.messages': 1000000\n",
    "}\n",
    "p = Producer(producer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(throughputs_mbs_per_sec: list, throughputs_msgs_per_sec: list, mb_per_exec: int, messages_per_exec: int):\n",
    "    \"\"\" Visualizes the benchmark results in plots.\n",
    "    \n",
    "    :param throughputs_mbs_per_sec: Throughput results, given in MBs / second\n",
    "    :param throughputs_msgs_per_sec: Throughput results, given in Messages / second\n",
    "    :param mb_per_exec: MBs of data processed in each benchmark execution\n",
    "    :param messages_per_exec: Amount of messages processed in each benchmark execution\n",
    "    \"\"\"\n",
    "    max_mbs_per_sec, min_mbs_per_sec, avg_mbs_per_sec = max(throughputs_mbs_per_sec), \\\n",
    "                                                        min(throughputs_mbs_per_sec), \\\n",
    "                                                        mean(throughputs_mbs_per_sec)\n",
    "    \n",
    "    max_msgs_per_sec, min_msgs_per_sec, avg_msgs_per_sec = max(throughputs_msgs_per_sec), \\\n",
    "                                                           min(throughputs_msgs_per_sec), \\\n",
    "                                                           mean(throughputs_msgs_per_sec)\n",
    "    \n",
    "    print(\"MB/s: | Max: {0} MB/s | Min: {1} MB/s | Avg: {2} MB/s\"\n",
    "          .format(max_mbs_per_sec, min_mbs_per_sec, avg_mbs_per_sec))\n",
    "    \n",
    "    print(\"Messages/s: | Max: {0} Messages/s | Min: {1} Messages/s | Avg: {2} Messages/s\"\n",
    "          .format(max_msgs_per_sec, min_msgs_per_sec, avg_msgs_per_sec))\n",
    "\n",
    "    # Plot Max, Min, Avg MB/s\n",
    "    fig = plt.figure(figsize=(9, 6), dpi=80)   \n",
    "    plt.bar(0, max_mbs_per_sec, width=1, color='navy')\n",
    "    plt.bar(1, avg_mbs_per_sec, width=1, color='darkcyan')\n",
    "    plt.bar(2, min_mbs_per_sec, width=1, color='skyblue')\n",
    "\n",
    "    plt.tick_params(labelleft=True, labelbottom=False)\n",
    "    plt.legend([\"Maximum MB/s\", \"Average MB/s\", \"Minimum MB/s\"], prop = {'size': 12}, bbox_to_anchor=(1.05, 0.8))\n",
    "    plt.title(\"Summarization of Throughput in MB/s\", fontsize=14, pad=12)\n",
    "    plt.show() \n",
    "    \n",
    "    # Plot Max, Min, Avg Messages/s\n",
    "    fig = plt.figure(figsize=(9, 6), dpi=80)\n",
    "    plt.bar(0, max_msgs_per_sec, width=1, color='navy')\n",
    "    plt.bar(1, avg_msgs_per_sec, width=1, color='darkcyan')\n",
    "    plt.bar(2, min_msgs_per_sec, width=1, color='skyblue')\n",
    "\n",
    "    plt.tick_params(labelleft=True, labelbottom=False)\n",
    "    plt.legend([\"Maximum MSGs/s\", \"Average MSG/s\", \"Minimum MSGs/s\"], prop = {'size': 12}, bbox_to_anchor=(1.05, 0.8))\n",
    "    plt.title(\"Summarization of Throughput in Messages/s\", fontsize=14, pad=12)\n",
    "    plt.show() \n",
    "        \n",
    "    # Plot MB/s results\n",
    "    executions = len(throughputs_mbs_per_sec)\n",
    "    x_labels = [\"Ex. {}\".format(i) for i in range(1, executions+1)]\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 6), dpi=80)\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    ax.bar(x_labels, throughputs_mbs_per_sec, color=\"navy\", width=0.7)\n",
    "    \n",
    "    ax.set_xlabel(\"Benchmark Executions\", fontsize=12)\n",
    "    ax.set_ylabel(\"Throughput in MB/s\", fontsize=12)\n",
    "    ax.set_title(\"Benchmark: Throughput ({} MB)\".format(mb_per_exec), fontsize=15, pad=12)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot Messages/s results\n",
    "    fig = plt.figure(figsize=(9, 6), dpi=80)\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    ax.bar(x_labels, throughputs_msgs_per_sec, color=\"darkcyan\", width=0.7)\n",
    "    \n",
    "    ax.set_xlabel(\"Benchmark Executions\", fontsize=12)\n",
    "    ax.set_ylabel(\"Throughput in Messages/s)\", fontsize=12)\n",
    "    ax.set_title(\"Benchmark: Throughput ({:,} Messages)\".format(messages_per_exec), fontsize=15, pad=12)\n",
    "    plt.show()\n",
    "\n",
    "def benchmark(mb_per_exec: int = 1000, exec_count: int = 10):\n",
    "    \"\"\" Executes a throughput benchmark procedure, e.g. the amount of MB per second that was \n",
    "        sent by the producer to the Broker. To get meaningful results, the benchmark procedure \n",
    "        is repeated exec_count times.\n",
    "        Default is ~ 1GB per execution, while executing 10 times.\n",
    "        \n",
    "        :param: mb_per_exec Amount of data to send per execution, given in MB. As the dataset is 10 MB large,\n",
    "                mb_per_exec % 10 = 0 should be true for the given argument.\n",
    "        :param exec_count: Amount of times to repeat the benchmark procedure\n",
    "    \"\"\"\n",
    "    print(\"Executing throughput benchmark ...\")\n",
    "    \n",
    "    throughputs_in_mb = [] # MB/s\n",
    "    throughputs_in_msgs = [] # Messages/s\n",
    "    \n",
    "    total_messages = int(DATASET_SIZE_IN_MSGS * (mb_per_exec / DATASET_SIZE_IN_MB))\n",
    "    dataset_iterations = int(mb_per_exec / DATASET_SIZE_IN_MB)\n",
    "    \n",
    "    with open(TWITTER_DATA_PATH, \"r\") as dataset:\n",
    "        for execution in range(exec_count):\n",
    "            \n",
    "            start = perf_counter()\n",
    "            for _ in range(dataset_iterations):\n",
    "                dataset.seek(0) # Jump back to first line \n",
    "                \n",
    "                for tweet in dataset:\n",
    "                    try:\n",
    "                        p.produce(KAFKA_TOPIC_TWITTER, value=tweet)\n",
    "                        p.poll(0)\n",
    "                    except BufferError:\n",
    "                        print('[INFO] Local producer queue is full (%d messages awaiting delivery): Trying again...\\n' % len(p)) \n",
    "                        p.poll(30)\n",
    "\n",
    "                        # Retry sending tweet\n",
    "                        p.produce(KAFKA_TOPIC_TWITTER, value=tweet)   \n",
    "            end = perf_counter()\n",
    "            \n",
    "            produce_time = float(end - start)\n",
    "            megabytes_per_second = mb_per_exec / produce_time\n",
    "            msgs_per_second = int(total_messages / produce_time)\n",
    "\n",
    "            print(\"{} Messages in {:.2f} seconds | {} Messages/s\"\n",
    "              .format(total_messages, produce_time, msgs_per_second))\n",
    "            \n",
    "            # Save results for later visualization\n",
    "            throughputs_in_mb.append(megabytes_per_second)\n",
    "            throughputs_in_msgs.append(msgs_per_second)\n",
    "            \n",
    "    p.flush(30)\n",
    "    \n",
    "    print(\"\\n\" + \"Benchmark procedure finished. Visualizing the results ...\")\n",
    "    visualize_results(throughputs_in_mb, throughputs_in_msgs, mb_per_exec, total_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing throughput benchmark ...\n",
      "1448500 Messages in 12.55 seconds | 115394 Messages/s\n",
      "1448500 Messages in 12.94 seconds | 111940 Messages/s\n",
      "1448500 Messages in 12.14 seconds | 119300 Messages/s\n",
      "1448500 Messages in 11.89 seconds | 121810 Messages/s\n"
     ]
    }
   ],
   "source": [
    "# Execute the benchmark\n",
    "benchmark(mb_per_exec=1000, exec_count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
