{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Kafka Streaming Analytics\n",
    "### One Broker Setup\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "#### Component: Consumer\n",
    "In this notebook Apache Kafka is going to be used and analyzed with reference to the streaming performance using the twitter dataset.\n",
    "\n",
    "In this case, we are going to use only one **Kafka Broker** that streams the data to the **Kafka Consumer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Python Client for Apache Kafka\n",
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies and set constants\n",
    "import matplotlib.pyplot as plt\n",
    "import platform, socket, json, psutil, logging, multiprocessing\n",
    "\n",
    "from time import time, perf_counter\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "from statistics import mean\n",
    "from datetime import datetime\n",
    "\n",
    "DATASET_SIZE_IN_MB = 10\n",
    "DATASET_SIZE_IN_MSGS = 14485\n",
    "\n",
    "CONSUMER_GROUP_ID = \"twitter-consumers\"\n",
    "KAFKA_TOPIC_TWITTER = \"twitter-stream\"\n",
    "\n",
    "def get_system_info():\n",
    "    \"\"\" Returns system information as JSON. \"\"\"\n",
    "    try:\n",
    "        info = {}\n",
    "        info['platform'] = platform.system()\n",
    "        info['platform-version'] = platform.version()\n",
    "        info['hostname'] = socket.gethostname()\n",
    "        info['ram'] = str(round(psutil.virtual_memory().total / (1024.0 **3))) + \" GB\"\n",
    "        info['vCPUs'] = multiprocessing.cpu_count()\n",
    "        info['architecture'] = platform.machine()\n",
    "\n",
    "        return json.dumps(info, indent=4)\n",
    "    except Exception as e:\n",
    "        logging.exception(e)\n",
    "        \n",
    "def assignment_report(consumer: Consumer, assignments: list):\n",
    "    \"\"\" Callback for printing the assigned topic partitions of the consumer \"\"\"\n",
    "    for assignment in assignments:\n",
    "        print(\"Consumer got assigned partition {0} for topic {1}.\".format(assignment.partition, assignment.topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder: Running Kafka Architecture required\n",
    "The following cells assume a running Apache Kafka Environment.\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "Furthermore, as we are using the **Consumer** component here, we have to make sure to start the consumer first before we start the Producer to ensure a performance measurement under realistic circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"platform\": \"Linux\",\n",
      "    \"platform-version\": \"#80-Ubuntu SMP Mon Apr 12 17:35:00 UTC 2021\",\n",
      "    \"hostname\": \"kafka-master\",\n",
      "    \"ram\": \"18 GB\",\n",
      "    \"vCPUs\": 4,\n",
      "    \"architecture\": \"x86_64\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print system information\n",
    "print(get_system_info())\n",
    "\n",
    "# Create Kafka Consumer\n",
    "consumer_config = {\n",
    "    \"bootstrap.servers\": \"localhost:9092\",\n",
    "    \"group.id\": CONSUMER_GROUP_ID,\n",
    "    \"client.id\": \"client-1\",\n",
    "    \"enable.auto.commit\": True,\n",
    "    \"session.timeout.ms\": 6000,\n",
    "    \"default.topic.config\": {\"auto.offset.reset\": \"smallest\"}\n",
    "}\n",
    "c = Consumer(consumer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(latency_results: list, throughputs_mbs_per_sec:list, throughputs_msgs_per_sec: list, mb_per_exec: int):\n",
    "    \"\"\" Visualizes the benchmark results in plots.\n",
    "    \n",
    "    :param latency_results: list of lists, each containing the latencies of a specific benchmark execution\n",
    "    :param throughputs_mbs_per_sec: Throughput results, given in MBs / second\n",
    "    :param throughputs_msgs_per_sec: Throughput results, given in Messages / second\n",
    "    :param mb_per_exec: Amount of data in MB received per execution\n",
    "    \"\"\"\n",
    "    # Latencies - per message\n",
    "    for exec_count, latencies in enumerate(latency_results):\n",
    "        fig = plt.figure(figsize=(10, 5), dpi=80)\n",
    "        ax = plt.axes()\n",
    "        \n",
    "        ax.plot([i for i in range(len(latencies))], latencies)\n",
    "        ax.set_ylabel(\"Latency (ms)\")\n",
    "        ax.set_title(\"Benchmark {0}: Latencies ({1} MB)\".format(exec_count+1, mb_per_exec), fontsize=15)\n",
    "        plt.tick_params(labelleft=True, labelbottom=False)\n",
    "        plt.show()\n",
    "    \n",
    "    # Latencies - percentiles\n",
    "    total_latencies = []\n",
    "    for subresult in latency_results:\n",
    "        total_latencies.extend(subresult)\n",
    "        \n",
    "    total_latencies.sort()\n",
    "        \n",
    "    p50_idx = int(len(total_latencies) * 50.0 / 100.0)\n",
    "    p75_idx = int(len(total_latencies) * 75.0 / 100.0)\n",
    "    p90_idx = int(len(total_latencies) * 90.0 / 100.0)\n",
    "    p95_idx = int(len(total_latencies) * 95.0 / 100.0)\n",
    "    p99_idx = int(len(total_latencies) * 99.0 / 100.0)\n",
    "        \n",
    "    p50 = total_latencies[p50_idx]\n",
    "    p75 = total_latencies[p75_idx]\n",
    "    p90 = total_latencies[p90_idx]\n",
    "    p95 = total_latencies[p95_idx]\n",
    "    p99 = total_latencies[p99_idx]\n",
    "    \n",
    "    print(\"============ Latency Results ============\")\n",
    "    print(\"| 50%: {0} | 75%: {1} | 90%: {2} | 95%: {3} | 99%: {4}\\n\"\n",
    "          .format(p50, p75, p90, p95, p99))\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 6), dpi=90)\n",
    "    ax = plt.axes()\n",
    "        \n",
    "    # Plot the ascendingly sorted latencies\n",
    "    xs = [i for i in range(1, len(total_latencies)+1)]\n",
    "    ys = total_latencies\n",
    "    ax.plot(xs, ys)\n",
    "        \n",
    "    # Set Percentile labels and visualize them by dashed lines\n",
    "    ax.set_xticks([p50_idx, p75_idx, p90_idx, p95_idx, p99_idx])\n",
    "    ax.set_xticklabels([\"50%\", \"75%\", \"90%\", \"95%\", \"99%\"])\n",
    "    ax.grid(axis=\"x\", color=\"green\", alpha=.4, linewidth=2, linestyle=\":\")\n",
    "        \n",
    "    ax.set_ylabel(\"Latency (ms)\", fontsize=12)\n",
    "    ax.set_title(\"Benchmark {0}: Latencies ({1} MB) - Percentiles\".format(exec_count+1, mb_per_exec), fontsize=15)\n",
    "        \n",
    "    fig.show()\n",
    "        \n",
    "    # Min, Max, Avg MB/s and Messages/s\n",
    "    max_mbs_per_sec, min_mbs_per_sec, avg_mbs_per_sec = max(throughputs_mbs_per_sec), \\\n",
    "                                                        min(throughputs_mbs_per_sec), \\\n",
    "                                                        mean(throughputs_mbs_per_sec)\n",
    "    \n",
    "    max_msgs_per_sec, min_msgs_per_sec, avg_msgs_per_sec = max(throughputs_msgs_per_sec), \\\n",
    "                                                           min(throughputs_msgs_per_sec), \\\n",
    "                                                           mean(throughputs_msgs_per_sec)\n",
    "    \n",
    "    print(\"============ Throughput Results ============\")\n",
    "    print(\"MB/s: | Max: {0} MB/s | Min: {1} MB/s | Avg: {2} MB/s\"\n",
    "          .format(max_mbs_per_sec, min_mbs_per_sec, avg_mbs_per_sec))\n",
    "    \n",
    "    print(\"Messages/s: | Max: {0} Messages/s | Min: {1} Messages/s | Avg: {2} Messages/s\"\n",
    "          .format(max_msgs_per_sec, min_msgs_per_sec, avg_msgs_per_sec))\n",
    "\n",
    "    # Plot Max, Min, Avg MB/s\n",
    "    fig = plt.figure(figsize=(10, 6), dpi=80)\n",
    "    plt.bar(0, max_mbs_per_sec, width=1, color='navy')\n",
    "    plt.bar(1, avg_mbs_per_sec, width=1, color='darkcyan')\n",
    "    plt.bar(2, min_mbs_per_sec, width=1, color='skyblue')\n",
    "\n",
    "    plt.tick_params(labelleft=True, labelbottom=False)\n",
    "    plt.legend([\"Maximum MB/s\", \"Average MB/s\", \"Minimum MB/s\"], prop = {'size': 12}, bbox_to_anchor=(1.05, 0.8))\n",
    "    plt.title(\"Summarization of Throughput in MB/s\", fontsize=14, pad=12)\n",
    "    plt.show() \n",
    "    \n",
    "    # Plot Max, Min, Avg Messages/s\n",
    "    fig = plt.figure(figsize=(10, 6), dpi=80)\n",
    "    plt.bar(0, max_msgs_per_sec, width=1, color='navy')\n",
    "    plt.bar(1, avg_msgs_per_sec, width=1, color='darkcyan')\n",
    "    plt.bar(2, min_msgs_per_sec, width=1, color='skyblue')\n",
    "\n",
    "    plt.tick_params(labelleft=True, labelbottom=False)\n",
    "    plt.legend([\"Maximum MSG/s\", \"Average MSG/s\", \"Minimum MSG/s\"], prop = {'size': 12}, bbox_to_anchor=(1.05, 0.8))\n",
    "    plt.title(\"Summarization of Throughput in Messages/s\", fontsize=14, pad=12)\n",
    "    plt.show() \n",
    "\n",
    "def benchmark(mb_per_exec: int = 1000, exec_count: int = 10):\n",
    "    \"\"\" Executes a latency benchmark procedure, e.g. the elapsed time between storing \n",
    "        a message in the logs at the Broker side (LogAppendTime) and receiving / consuming it \n",
    "        on the Consumer side. To get meaningful results, the benchmark procedure is repeated\n",
    "        exec_count times.\n",
    "        Default is ~ 1GB per execution, while executing 10 times.\n",
    "\n",
    "        :param mb_per_exec: Amount of data to expect (sent by the producer) per execution, given in MB.\n",
    "                            As the dataset is 10 MB large, mb_per_exec % 10 = 0 should be true for the\n",
    "                            given argument.\n",
    "        :param exec_count: Amount of times to repeat the benchmark procedure\n",
    "    \"\"\"\n",
    "    print(\"Executing latency benchmark. Waiting for Producer sending data ...\")        \n",
    "    \n",
    "    latency_results = []\n",
    "    throughputs_in_mb = [] # MB/s\n",
    "    throughputs_in_msgs = [] # Messages/s\n",
    "    \n",
    "    total_messages = int(DATASET_SIZE_IN_MSGS * (mb_per_exec / DATASET_SIZE_IN_MB))\n",
    "        \n",
    "    c.subscribe([KAFKA_TOPIC_TWITTER], on_assign=assignment_report)\n",
    "    for execution in range(exec_count):\n",
    "        msg_counter = 0\n",
    "        latencies = []\n",
    "        \n",
    "        start = None\n",
    "        while msg_counter < total_messages:               \n",
    "            msg = c.poll(0.5)\n",
    "\n",
    "            if msg is None:\n",
    "                continue\n",
    "            elif not msg.error():\n",
    "                msg_counter += 1\n",
    "                \n",
    "                # Start the timer once the first message was received\n",
    "                if msg_counter == 1:\n",
    "                    start = perf_counter()\n",
    "                    print(\"Starting consuming: {}\".format(datetime.utcnow().isoformat(sep=' ', timespec='milliseconds')))\n",
    "                    \n",
    "                latency = (time() * 1000) - msg.timestamp()[1]\n",
    "                latencies.append(latency)\n",
    "            elif msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                print(\"End of partition reached {}/{}\".format(msg.topic(), msg.partition()))\n",
    "                print(\"Messages consumed: {}\".format(msg_counter))\n",
    "            else:\n",
    "                print(\"Error occured: {}\".format(msg.error().str()))\n",
    "        end = perf_counter()\n",
    "        print(\"Stopping consuming: {}\".format(datetime.utcnow().isoformat(sep=' ', timespec='milliseconds')))\n",
    "        \n",
    "        consume_time = float(end - start)\n",
    "        megabytes_per_second = mb_per_exec / consume_time\n",
    "        msgs_per_second = total_messages / consume_time\n",
    "        \n",
    "        print(\"{} Messages in {:.2f} seconds | {} Messages/s\"\n",
    "              .format(total_messages, consume_time, int(total_messages / consume_time)))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Save results for later visualization\n",
    "        latency_results.append(latencies)\n",
    "        throughputs_in_mb.append(megabytes_per_second)\n",
    "        throughputs_in_msgs.append(msgs_per_second)\n",
    "    \n",
    "    c.close()\n",
    "    \n",
    "    print(\"\\n\" + \"Benchmark procedure finished. Visualizing the results ...\")\n",
    "    visualize_results(latency_results, throughputs_in_mb, throughputs_in_msgs, mb_per_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing latency benchmark. Waiting for Producer sending data ...\n",
      "Consumer got assigned partition 0 for topic twitter-stream.\n",
      "Consumer got assigned partition 1 for topic twitter-stream.\n",
      "Consumer got assigned partition 2 for topic twitter-stream.\n",
      "Consumer got assigned partition 3 for topic twitter-stream.\n",
      "\n",
      "\n",
      "Consumer got assigned partition 0 for topic twitter-stream.\n",
      "Consumer got assigned partition 1 for topic twitter-stream.\n",
      "\n",
      "\n",
      "Consumer got assigned partition 0 for topic twitter-stream.\n",
      "Consumer got assigned partition 1 for topic twitter-stream.\n",
      "\n",
      "\n",
      "Consumer got assigned partition 0 for topic twitter-stream.\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:44:22.554\n",
      "Stopping consuming: 2021-04-30 11:44:36.044\n",
      "1448500 Messages in 13.49 seconds | 107373 Messages/s\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:44:36.046\n",
      "Stopping consuming: 2021-04-30 11:44:47.132\n",
      "1448500 Messages in 11.09 seconds | 130661 Messages/s\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:44:47.134\n",
      "Stopping consuming: 2021-04-30 11:44:58.889\n",
      "1448500 Messages in 11.76 seconds | 123223 Messages/s\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:44:58.890\n",
      "Stopping consuming: 2021-04-30 11:45:09.922\n",
      "1448500 Messages in 11.03 seconds | 131299 Messages/s\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:45:09.923\n",
      "Stopping consuming: 2021-04-30 11:45:20.587\n",
      "1448500 Messages in 10.66 seconds | 135837 Messages/s\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:45:20.588\n",
      "Stopping consuming: 2021-04-30 11:45:31.553\n",
      "1448500 Messages in 10.97 seconds | 132099 Messages/s\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:45:31.555\n",
      "Stopping consuming: 2021-04-30 11:45:42.246\n",
      "1448500 Messages in 10.69 seconds | 135489 Messages/s\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:45:42.246\n",
      "Stopping consuming: 2021-04-30 11:45:53.123\n",
      "1448500 Messages in 10.88 seconds | 133176 Messages/s\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:45:53.123\n",
      "Stopping consuming: 2021-04-30 11:46:04.245\n",
      "1448500 Messages in 11.12 seconds | 130241 Messages/s\n",
      "\n",
      "\n",
      "Starting consuming: 2021-04-30 11:46:04.246\n"
     ]
    }
   ],
   "source": [
    "# Execute the benchmark\n",
    "benchmark(mb_per_exec=1000, exec_count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
