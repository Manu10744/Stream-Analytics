{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies and set constants\n",
    "from pyflink.datastream.functions import ProcessFunction\n",
    "from pyflink.common.serialization import SimpleStringSchema, SerializationSchema\n",
    "from pyflink.common.typeinfo import Types\n",
    "from pyflink.datastream import StreamExecutionEnvironment, TimeCharacteristic\n",
    "from pyflink.datastream.connectors import FlinkKafkaConsumer, FlinkKafkaProducer\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# specifiy Kafka producer and Kafka consumer servers (only one server in this case)\n",
    "producer_props = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'queue.buffering.max.messages': '1000000'\n",
    "}\n",
    "\n",
    "consumer_props = {\n",
    "    \"bootstrap.servers\": \"localhost:9092\",\n",
    "    \"group.id\": \"twitter-consumers\",\n",
    "    \"client.id\": \"client-1\",\n",
    "}\n",
    "\n",
    "# topic from which to read\n",
    "KAFKA_TOPIC = \"twitter-stream\"\n",
    "# path to Kafka connector dependency\n",
    "KAFKA_CONNECTOR_JAR = \"file:///home/ubuntu/flink-sql-connector-kafka_2.11-1.12.2.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom process-function. Executed upon record arrival\n",
    "class MyProcessFunction(ProcessFunction):\n",
    "\n",
    "    def process_element(self, value, ctx: 'ProcessFunction.Context'):\n",
    "        # global might not be ideal here (parallelism possible?) but currently nothing else comes to mind\n",
    "        global records_received\n",
    "        global start_time\n",
    "        global iterations\n",
    "        cur_time = time.time()\n",
    "        # ctx.timestamp() will return the LogAppendTime set by Kafka\n",
    "        latency = (cur_time * 1000) - ctx.timestamp()\n",
    "        result = str(latency)\n",
    "        yield result\n",
    "\n",
    "# set up execution environment\n",
    "env = StreamExecutionEnvironment.get_execution_environment()\n",
    "# EventTime --> Flink will look for pre-assigned timestamp\n",
    "env.set_stream_time_characteristic(TimeCharacteristic.EventTime)\n",
    "\n",
    "# Add the Kafka Connector Dependency\n",
    "env.add_jars(KAFKA_CONNECTOR_JAR)\n",
    "env.add_classpaths(KAFKA_CONNECTOR_JAR)\n",
    "\n",
    "# define Kafka source and sink (mind the different topics)\n",
    "kafka_consumer = FlinkKafkaConsumer(\"twitter-stream\", SimpleStringSchema(), consumer_props)\n",
    "kafka_producer = FlinkKafkaProducer(\"twitter-stream-results\", SimpleStringSchema(), producer_props)\n",
    "\n",
    "# create stream \n",
    "stream = env.add_source(kafka_consumer)\n",
    "stream.process(MyProcessFunction(), output_type=Types.STRING()) \\\n",
    "      .add_sink(kafka_producer)\n",
    "\n",
    "# execute job\n",
    "env.execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
